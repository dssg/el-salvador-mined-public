{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%config IPCompleter.greedy=True\n",
    "\n",
    "import yaml\n",
    "import psycopg2\n",
    "import os\n",
    "import os.path\n",
    "import sys\n",
    "\n",
    "# Set the path\n",
    "home_dir = os.getcwd()\n",
    "credential_dir = os.path.join('../../config')\n",
    "\n",
    "def create_pgconn(credentials_yaml):\n",
    "    with open(credentials_yaml) as f:\n",
    "        configs = yaml.load(f)\n",
    "    try: \n",
    "        conn = psycopg2.connect(\"dbname='{}' user='{}' host='{}' password='{}'\".format(\n",
    "            configs['DB_name'],\n",
    "            configs['user'],\n",
    "            configs['host'],\n",
    "            configs['password']))\n",
    "    except Exception as e: \n",
    "        print(\"Error connecting to db.\")\n",
    "        raise e\n",
    "    conn.set_client_encoding('latin_1')\n",
    "    cur = conn.cursor()\n",
    "    cur.execute(\"SET ROLE \" + configs['role'])\n",
    "    return conn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting up a connection to the server\n",
    "\n",
    "credentials_yaml = os.path.join(credential_dir, 'db_creds.yml') #example file on hitchikers repo\n",
    "conn = create_pgconn(credentials_yaml)\n",
    "\n",
    "def sql(query, conn=conn):\n",
    "    return pd.read_sql(query, conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The renaming uses the ordering of the new column names in 1_column_mapping.csv, combined with the automatic naming of columns by csvkit (a,b,c...aa,bb,cc...aaa,bbb,...)\n",
    "with open('../../../../garfield/1_column_mapping.csv', 'r') as fil:\n",
    "    col_file = fil.read()\n",
    "alphabet = list(map(chr, range(97, 123)))\n",
    "def multi_alphabet(n_times):\n",
    "    full_alph = []\n",
    "    for n in range(1, n_times+1):\n",
    "        full_alph += [''.join(x) for x in zip(*[alphabet]*n)]\n",
    "    return full_alph\n",
    "old_cols = multi_alphabet(12)\n",
    "col_map = dict()\n",
    "all_new_cols = []\n",
    "for pair in col_file.split('\\n'):\n",
    "    lst = pair.split(',')\n",
    "    col_map[lst[0]] = dict()\n",
    "    new = []\n",
    "    old = []\n",
    "    for idx, new_col in enumerate(lst[1:]):\n",
    "        if new_col != '':\n",
    "            old += ['g%d' %idx] #old_cols[idx]]\n",
    "            new += [new_col]\n",
    "    col_map[lst[0]]['old'] = old\n",
    "    col_map[lst[0]]['new'] = new\n",
    "    all_new_cols += new\n",
    "union = set(all_new_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cur = conn.cursor()\n",
    "cmnd = 'year smallint, ' + ' varchar, '.join(union) + ' varchar'  # This creates a list of column names that will be used in the joined table\n",
    "cur.execute(\"\"\"drop table if exists preproc.\"1_joined\";\"\"\")\n",
    "cur.execute(\"\"\"create table if not exists preproc.\"1_joined\" (%s);\"\"\" %cmnd)\n",
    "conn.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iterates over all tables in raw (with columns a0, a1, a2...), inserting into a joined preprocessing table (with columns nie, dpto_code_ce, year...)\n",
    "cur = conn.cursor()\n",
    "for table_name, cols in col_map.items():\n",
    "    print(table_name)\n",
    "    year = table_name[-4:]\n",
    "    cur.execute(\"\"\"insert into preproc.\"1_joined\" (year, %s) select %s, %s from raw.\"%s\";\"\"\" %(','.join(cols['new']), int(year), ','.join(cols['old']), table_name))\n",
    "conn.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../../../../garfield/1_column_mapping_types.csv', 'r') as fil:\n",
    "    col_file = fil.read()\n",
    "col_types = dict()\n",
    "for pair in col_file.split('\\n'):\n",
    "    split = pair.split(',')\n",
    "    if split[1] != '':\n",
    "        col_types[split[0]] = split[1]\n",
    "    else:\n",
    "        col_types[split[0]] = 'varchar'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Changing the column types and removing empty strings\n",
    "cur = conn.cursor()\n",
    "for col, col_typ in col_types.items():\n",
    "    print(col)\n",
    "    if col in union:\n",
    "        try:\n",
    "            if col_typ == 'bool':\n",
    "                cur.execute(\"\"\"ALTER TABLE preproc.\"1_joined\" ALTER COLUMN %s TYPE bool\n",
    "        USING CASE %s \n",
    "        WHEN 'SÃ­' THEN '1'::bool\n",
    "        WHEN 'No' THEN '0'::bool\n",
    "        WHEN '1' then '1'::bool\n",
    "        WHEN '0' then '0'::bool\n",
    "        END;\"\"\" %(col, col))\n",
    "            elif 'int' in col_typ:\n",
    "                cur.execute(\"\"\"ALTER TABLE preproc.\"1_joined\" ALTER COLUMN %s TYPE %s using NULLIF(%s, '')::numeric::%s;\"\"\" %(col, col_typ, col, col_typ))\n",
    "            else:\n",
    "                cur.execute(\"\"\"ALTER TABLE preproc.\"1_joined\" ALTER COLUMN %s TYPE %s using NULLIF(%s, '')::%s;\"\"\" %(col, col_typ, col, col_typ))\n",
    "        except Exception as e:\n",
    "            print('Failed because: %s' %e)\n",
    "            conn = create_pgconn(credentials_yaml)\n",
    "            cur = conn.cursor()\n",
    "#     else:\n",
    "#         LOGGER WARN\n",
    "# conn.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/mnt/data/projects/el_salvador_mined_education/garfield/1._Censo_matricular_-_Centros_educativos/Base_de_Centros_Escolares_Censo_2016.csv') as fil:\n",
    "    read = fil.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "headers = read[8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "headers.split('^')[-22]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "read[16].split('^')[-22]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
