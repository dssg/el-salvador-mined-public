{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Index baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%config IPCompleter.greedy=True\n",
    "\n",
    "import yaml\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import psycopg2\n",
    "#from os import path\n",
    "import os\n",
    "import os.path\n",
    "import sys\n",
    "import numpy as np\n",
    "from sqlalchemy import create_engine\n",
    "\n",
    "pd.set_option(\"display.max_rows\", 50)\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "# Set the path\n",
    "home_dir = os.getcwd()\n",
    "credential_dir = os.path.join('/mnt/data/projects/el_salvador_mined_education', 'ana', 'db_credentials')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_pgconn(credentials_yaml):\n",
    "    with open(credentials_yaml) as f:\n",
    "        configs = yaml.load(f)\n",
    "    try: \n",
    "        conn = psycopg2.connect(\"dbname='{}' user='{}' host='{}' password='{}'\".format(\n",
    "            configs['database'],\n",
    "            configs['user'],\n",
    "            configs['host'],\n",
    "            configs['password']))\n",
    "    except: \n",
    "        print(\"Error connecting to db.\")\n",
    "\n",
    "    cur = conn.cursor()\n",
    "    cur.execute(\"SET ROLE \" + configs['role'])\n",
    "    return conn\n",
    "credentials_yaml = os.path.join(credential_dir, 'avaldivia_elsalvador.yaml') #example file on hitchikers repo\n",
    "conn = create_pgconn(credentials_yaml)\n",
    "def sql(query, conn=conn):\n",
    "    return pd.read_sql(query, conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Index data\n",
    "df = sql(\"\"\"\n",
    "    SELECT a.student, a. year_range, a.school, a.school_index_avg, b.label from results.features_aggregate a LEFT JOIN staging.labels b\n",
    "    ON a.student = b.student AND a.year_range = b.year_range\n",
    "    WHERE a.school_index_avg IS NOT NULL \n",
    "    AND b.label IS NOT NULL\n",
    "    AND  a.school_index_avg IS NOT NULL\n",
    "    AND extract(year from lower(a.year_range)) = '2016'; \n",
    "\"\"\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test and score vectors\n",
    "y_test = df.label\n",
    "y_score = df.school_index_avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for ploting prec and recall at k\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "def plot_precision_recall_n(y_true, y_prob, model_name, output_type):\n",
    "    y_score = y_prob\n",
    "    precision_curve, recall_curve, pr_thresholds = precision_recall_curve(y_true, y_score)\n",
    "    precision_curve = precision_curve[:-1]\n",
    "    recall_curve = recall_curve[:-1]\n",
    "    pct_above_per_thresh = []\n",
    "    number_scored = len(y_score)\n",
    "    for value in pr_thresholds:\n",
    "        num_above_thresh = len(y_score[y_score>=value])\n",
    "        pct_above_thresh = num_above_thresh / float(number_scored)\n",
    "        pct_above_per_thresh.append(pct_above_thresh)\n",
    "    pct_above_per_thresh = np.array(pct_above_per_thresh)\n",
    "\n",
    "    plt.clf()\n",
    "    fig, ax1 = plt.subplots()\n",
    "    ax1.plot(pct_above_per_thresh, precision_curve, 'b')\n",
    "    ax1.set_xlabel('percent of population')\n",
    "    ax1.set_ylabel('precision', color='b')\n",
    "    ax2 = ax1.twinx()\n",
    "    ax2.plot(pct_above_per_thresh, recall_curve, 'r')\n",
    "    ax2.set_ylabel('recall', color='r')\n",
    "    ax1.set_ylim([0,1])\n",
    "    ax1.set_ylim([0,1])\n",
    "    ax2.set_xlim([0,1])\n",
    "\n",
    "    # name = model_name\n",
    "    # plt.title(name)\n",
    "    if (output_type == 'save'):\n",
    "        plt.savefig(name)\n",
    "    elif (output_type == 'show'):\n",
    "        plt.show()\n",
    "    else: plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot precision and recall at k\n",
    "plot_precision_recall_n(y_test, y_score, \"Baseline_DT\" ,'show')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute AUC\n",
    "from sklearn.metrics import roc_auc_score\n",
    "print('AUC:', roc_auc_score(y_test, y_score))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
